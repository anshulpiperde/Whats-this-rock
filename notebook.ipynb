{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9pFFADG0ibV"
      },
      "source": [
        "## To-do list\n",
        "- [ ] 1) Create MobileNet similar to efficientnet.py\n",
        "- [ ] 2) add data augmentation to argsparse or use a config.json or yaml file\n",
        "- [ ] 3) Remove bad images and balance images using smote\n",
        "- [ ] 4) Add more data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h_Jo1jjevo2",
        "outputId": "edbd74c4-193c-4ece-c311-4358064bc574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Whats-this-rock'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 466 (delta 9), reused 13 (delta 4), pack-reused 446\u001b[K\n",
            "Receiving objects: 100% (466/466), 603.17 KiB | 26.22 MiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n",
            "/content/Whats-this-rock\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!rm -rf Whats-this-rock/\n",
        "!git clone https://github.com/udaylunawat/Whats-this-rock.git\n",
        "%cd Whats-this-rock/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtV5lSDSBDAt",
        "outputId": "6772ae55-650b-4780-d077-294039cddce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  1 18:22:07 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj8_Qvwne8e7"
      },
      "source": [
        "## Uploading Kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "Xdg9VTNbFeCc",
        "outputId": "d6b21aa8-c6b7-4e44-ec51-cc34b24fe517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Kaggle.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-188f924d-e08a-4046-9c99-ddcc90846fc2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-188f924d-e08a-4046-9c99-ddcc90846fc2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "print(\"Upload Kaggle.json\")\n",
        "files.upload();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUSuNjlQZSi-"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JGBevmSfCj1",
        "outputId": "4cfd0e94-55a0-4d6d-fb82-8e5feb002cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 15.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 26.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 58.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qq -r requirements-dev.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rEMinI4fChL"
      },
      "outputs": [],
      "source": [
        "!sh setup.sh\n",
        "!python preprocess.py --root data/1_extracted/Rock_Dataset/ \\\n",
        "                      --undersample\n",
        "                      --remove_class minerals\n",
        "# data/1_extracted/Rock_Dataset/sedimentary\\ rocks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('training_data.csv')\n",
        "data['classes'].value_counts()"
      ],
      "metadata": {
        "id": "UXRCs-nOrxx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.json\n",
        "\n",
        "{\n",
        "    \"root_dir\" : \"data/1_extracted/Rock_Dataset/\",\n",
        "    \"project_name\" : \"rock_classification\",\n",
        "    \"model_name\" : \"efficientnet\",\n",
        "    \"sample_size\" : 1.0,\n",
        "    \"augment\": \"False\",\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"learning_rate\" : 0.1,\n",
        "    \"batch_size\" : 128,\n",
        "    \"epochs\" : 50,\n",
        "    \"image_size\" : 224,\n",
        "    \"trainable\" : false\n",
        "}"
      ],
      "metadata": {
        "id": "HrgJfZD7sGq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e2f958-cf0a-43e1-cb96-2b4ae754db64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- use dry_run if you don't want to log to wandb"
      ],
      "metadata": {
        "id": "TGNLmkaSPFd1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6xHF-hb_j_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d895fe3-6403-4d4d-a858-b36d12d80a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.17\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "Augmentation - False\r\n",
            "model name - efficientnet\r\n",
            "config - Namespace(augment='False', batch_size=128, dry_run=True, epochs=50, image_size=224, learning_rate=0.1, model_name='efficientnet', notes='', optimizer='Adam', pretrained_trainable=False, project_name='rock_classification', sample_size=1.0)\r\n",
            "Found 3125 validated image filenames belonging to 4 classes.\r\n",
            "Found 781 validated image filenames belonging to 4 classes.\r\n",
            "Found 434 validated image filenames.\n",
            "2022-06-01 18:57:35.631974: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetv2-b0 (Function  (None, 7, 7, 1280)       5919312   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1311744   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,510,164\n",
            "Trainable params: 1,590,852\n",
            "Non-trainable params: 5,919,312\n",
            "_________________________________________________________________\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 28s 748ms/step - loss: 50825.2656 - f1_score: 0.2649 - accuracy: 0.2694 - val_loss: 19862.0898 - val_f1_score: 0.2273 - val_accuracy: 0.2894 - lr: 0.1000 - _timestamp: 1654109885.0000 - _runtime: 33.0000\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 14s 542ms/step - loss: 5503.0303 - f1_score: 0.3504 - accuracy: 0.3523 - val_loss: 839.3320 - val_f1_score: 0.4455 - val_accuracy: 0.4571 - lr: 0.1000 - _timestamp: 1654109918.0000 - _runtime: 66.0000\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 14s 549ms/step - loss: 514.9742 - f1_score: 0.4370 - accuracy: 0.4374 - val_loss: 129.7488 - val_f1_score: 0.4945 - val_accuracy: 0.5211 - lr: 0.1000 - _timestamp: 1654109932.0000 - _runtime: 80.0000\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 14s 535ms/step - loss: 151.7803 - f1_score: 0.4562 - accuracy: 0.4563 - val_loss: 61.5144 - val_f1_score: 0.5703 - val_accuracy: 0.5762 - lr: 0.0500 - _timestamp: 1654109952.0000 - _runtime: 100.0000\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 14s 546ms/step - loss: 81.3440 - f1_score: 0.4817 - accuracy: 0.4819 - val_loss: 43.1969 - val_f1_score: 0.5520 - val_accuracy: 0.5595 - lr: 0.0500 - _timestamp: 1654109973.0000 - _runtime: 121.0000\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 14s 553ms/step - loss: 54.2407 - f1_score: 0.4820 - accuracy: 0.4816 - val_loss: 27.5988 - val_f1_score: 0.5688 - val_accuracy: 0.5749 - lr: 0.0250 - _timestamp: 1654109986.0000 - _runtime: 134.0000\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 13s 525ms/step - loss: 42.4427 - f1_score: 0.4813 - accuracy: 0.4800 - val_loss: 18.8492 - val_f1_score: 0.5713 - val_accuracy: 0.5736 - lr: 0.0250 - _timestamp: 1654109999.0000 - _runtime: 148.0000\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 14s 544ms/step - loss: 33.4543 - f1_score: 0.4901 - accuracy: 0.4902 - val_loss: 18.3168 - val_f1_score: 0.5612 - val_accuracy: 0.5698 - lr: 0.0125 - _timestamp: 1654110020.0000 - _runtime: 168.0000\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 14s 550ms/step - loss: 30.6625 - f1_score: 0.4842 - accuracy: 0.4832 - val_loss: 16.5800 - val_f1_score: 0.5528 - val_accuracy: 0.5544 - lr: 0.0125 - _timestamp: 1654110034.0000 - _runtime: 182.0000\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 14s 534ms/step - loss: 28.2178 - f1_score: 0.4919 - accuracy: 0.4906 - val_loss: 14.6919 - val_f1_score: 0.5669 - val_accuracy: 0.5723 - lr: 0.0063 - _timestamp: 1654110048.0000 - _runtime: 196.0000\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 14s 561ms/step - loss: 26.0741 - f1_score: 0.4949 - accuracy: 0.4947 - val_loss: 13.4525 - val_f1_score: 0.5512 - val_accuracy: 0.5557 - lr: 0.0063 - _timestamp: 1654110068.0000 - _runtime: 216.0000\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 14s 564ms/step - loss: 23.8106 - f1_score: 0.4880 - accuracy: 0.4870 - val_loss: 13.2634 - val_f1_score: 0.5682 - val_accuracy: 0.5723 - lr: 0.0031 - _timestamp: 1654110089.0000 - _runtime: 237.0000\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 13s 525ms/step - loss: 23.3353 - f1_score: 0.4836 - accuracy: 0.4826 - val_loss: 13.6960 - val_f1_score: 0.5618 - val_accuracy: 0.5659 - lr: 0.0031 - _timestamp: 1654110103.0000 - _runtime: 251.0000\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 13s 529ms/step - loss: 22.0772 - f1_score: 0.5041 - accuracy: 0.5037 - val_loss: 12.6066 - val_f1_score: 0.5667 - val_accuracy: 0.5711 - lr: 0.0016 - _timestamp: 1654110115.0000 - _runtime: 263.0000\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 14s 570ms/step - loss: 19.9163 - f1_score: 0.4952 - accuracy: 0.4944 - val_loss: 12.3935 - val_f1_score: 0.5709 - val_accuracy: 0.5723 - lr: 0.0016 - _timestamp: 1654110137.0000 - _runtime: 285.0000\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 13s 538ms/step - loss: 21.9155 - f1_score: 0.4806 - accuracy: 0.4790 - val_loss: 12.3789 - val_f1_score: 0.5764 - val_accuracy: 0.5775 - lr: 7.8125e-04 - _timestamp: 1654110157.0000 - _runtime: 305.0000\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 14s 545ms/step - loss: 21.5548 - f1_score: 0.5037 - accuracy: 0.5030 - val_loss: 11.9322 - val_f1_score: 0.5710 - val_accuracy: 0.5762 - lr: 7.8125e-04 - _timestamp: 1654110177.0000 - _runtime: 325.0000\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 14s 557ms/step - loss: 19.9276 - f1_score: 0.4904 - accuracy: 0.4886 - val_loss: 11.8646 - val_f1_score: 0.5747 - val_accuracy: 0.5762 - lr: 3.9063e-04 - _timestamp: 1654110191.0000 - _runtime: 339.0000\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 13s 534ms/step - loss: 20.9319 - f1_score: 0.4942 - accuracy: 0.4938 - val_loss: 11.9760 - val_f1_score: 0.5699 - val_accuracy: 0.5736 - lr: 3.9063e-04 - _timestamp: 1654110205.0000 - _runtime: 353.0000\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 13s 541ms/step - loss: 20.4792 - f1_score: 0.4958 - accuracy: 0.4960 - val_loss: 11.7922 - val_f1_score: 0.5738 - val_accuracy: 0.5762 - lr: 1.9531e-04 - _timestamp: 1654110218.0000 - _runtime: 366.0000\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 13s 528ms/step - loss: 21.1022 - f1_score: 0.4905 - accuracy: 0.4890 - val_loss: 11.7209 - val_f1_score: 0.5723 - val_accuracy: 0.5749 - lr: 1.9531e-04 - _timestamp: 1654110238.0000 - _runtime: 386.0000\n",
            "Confusion Matrix with Validation data\n",
            "[[  0  11  94  94]\n",
            " [  0  14  79 107]\n",
            " [  0  13  98 101]\n",
            " [  0  18  82  70]]\n",
            "Classification Report\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "{'igneous rocks': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 199}, 'metamorphic rocks': {'precision': 0.25, 'recall': 0.07, 'f1-score': 0.10937500000000001, 'support': 200}, 'minerals': {'precision': 0.2776203966005666, 'recall': 0.46226415094339623, 'f1-score': 0.34690265486725663, 'support': 212}, 'sedimentary rocks': {'precision': 0.1881720430107527, 'recall': 0.4117647058823529, 'f1-score': 0.2583025830258303, 'support': 170}, 'accuracy': 0.2330345710627401, 'macro avg': {'precision': 0.17894810990282983, 'recall': 0.2360072142064373, 'f1-score': 0.17864505947327175, 'support': 781}, 'weighted avg': {'precision': 0.18033901586574658, 'recall': 0.2330345710627401, 'f1-score': 0.1783992342461582, 'support': 781}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     accuracy ▁▃▆▇▇▇▇█▇███▇██▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        epoch ▁▁▂▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇▇██\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     f1_score ▁▄▆▇▇▇▇█▇███▇██▇█████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         loss █▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:           lr ███▄▄▃▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  num_classes ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_accuracy ▁▅▇█████▇█▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_f1_score ▁▅▆███████▇██████████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     val_loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      accuracy 0.48896\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    best_epoch 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: best_val_loss 11.72093\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         epoch 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      f1_score 0.49047\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          loss 21.10222\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            lr 0.0002\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   num_classes 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  val_accuracy 0.5749\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  val_f1_score 0.57227\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      val_loss 11.72093\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/Whats-this-rock/wandb/offline-run-20220601_185731-eetrnlcr\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20220601_185731-eetrnlcr/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python train.py --dry_run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa9mUak6P7bm"
      },
      "source": [
        "# Weights and Biases Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt6c5b0rjC45",
        "outputId": "5fdfa4e6-e713-4b05-f89e-d574f8de5f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = '3pw3l2bd'\n",
        "%cd /content/Whats-this-rock\n",
        "!wandb agent rock-classifiers/Whats-this-rock/$sweep_id"
      ],
      "metadata": {
        "id": "kAPZwDqbr2fj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20aead28-c282-4db7-9c1e-a03a1e0f38ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Whats-this-rock\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
            "2022-06-01 04:37:13,010 - wandb.wandb_agent - INFO - Running runs: []\n",
            "2022-06-01 04:37:13,254 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2022-06-01 04:37:13,255 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\taugment: True\n",
            "\tbatch_size: 64\n",
            "\tepochs: 100\n",
            "\tlearning_rate: 0.01\n",
            "\tmodel: efficientnet\n",
            "\toptimizer: RMS\n",
            "\tsample_size: 1\n",
            "\tsize: 224\n",
            "2022-06-01 04:37:13,256 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --augment=True --batch_size=64 --epochs=100 --learning_rate=0.01 --model=efficientnet --optimizer=RMS --sample_size=1 --size=224\n",
            "usage: train.py [-h] [-n NOTES] [-p PROJECT_NAME] [-m MODEL_NAME]\n",
            "                [-sample SAMPLE_SIZE] [-lr LEARNING_RATE] [-b BATCH_SIZE]\n",
            "                [-e EPOCHS] [-o OPTIMIZER] [-size IMAGE_SIZE] [-aug] [-q]\n",
            "                [-trainable]\n",
            "train.py: error: argument -aug/--augment: ignored explicit argument 'True'\n",
            "2022-06-01 04:37:18,267 - wandb.wandb_agent - INFO - Running runs: ['oursjtlz']\n",
            "2022-06-01 04:37:18,267 - wandb.wandb_agent - INFO - Cleaning up finished run: oursjtlz\n",
            "2022-06-01 04:37:18,478 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2022-06-01 04:37:18,478 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\taugment: False\n",
            "\tbatch_size: 128\n",
            "\tepochs: 100\n",
            "\tlearning_rate: 0.01\n",
            "\tmodel: efficientnet\n",
            "\toptimizer: RMS\n",
            "\tsample_size: 1\n",
            "\tsize: 224\n",
            "2022-06-01 04:37:18,479 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --augment=False --batch_size=128 --epochs=100 --learning_rate=0.01 --model=efficientnet --optimizer=RMS --sample_size=1 --size=224\n",
            "usage: train.py [-h] [-n NOTES] [-p PROJECT_NAME] [-m MODEL_NAME]\n",
            "                [-sample SAMPLE_SIZE] [-lr LEARNING_RATE] [-b BATCH_SIZE]\n",
            "                [-e EPOCHS] [-o OPTIMIZER] [-size IMAGE_SIZE] [-aug] [-q]\n",
            "                [-trainable]\n",
            "train.py: error: argument -aug/--augment: ignored explicit argument 'False'\n",
            "2022-06-01 04:37:23,490 - wandb.wandb_agent - INFO - Running runs: ['3nmjyxgl']\n",
            "2022-06-01 04:37:23,490 - wandb.wandb_agent - INFO - Cleaning up finished run: 3nmjyxgl\n",
            "2022-06-01 04:37:23,787 - wandb.wandb_agent - INFO - Agent received command: run\n",
            "2022-06-01 04:37:23,787 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
            "\taugment: False\n",
            "\tbatch_size: 64\n",
            "\tepochs: 100\n",
            "\tlearning_rate: 0.01\n",
            "\tmodel: mobilenet\n",
            "\toptimizer: Adam\n",
            "\tsample_size: 1\n",
            "\tsize: 224\n",
            "2022-06-01 04:37:23,789 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --augment=False --batch_size=64 --epochs=100 --learning_rate=0.01 --model=mobilenet --optimizer=Adam --sample_size=1 --size=224\n",
            "usage: train.py [-h] [-n NOTES] [-p PROJECT_NAME] [-m MODEL_NAME]\n",
            "                [-sample SAMPLE_SIZE] [-lr LEARNING_RATE] [-b BATCH_SIZE]\n",
            "                [-e EPOCHS] [-o OPTIMIZER] [-size IMAGE_SIZE] [-aug] [-q]\n",
            "                [-trainable]\n",
            "train.py: error: argument -aug/--augment: ignored explicit argument 'False'\n",
            "2022-06-01 04:37:28,796 - wandb.wandb_agent - INFO - Running runs: ['eo3iynhu']\n",
            "2022-06-01 04:37:28,796 - wandb.wandb_agent - ERROR - Detected 3 failed runs in the first 60 seconds, shutting down.\n",
            "2022-06-01 04:37:28,796 - wandb.wandb_agent - INFO - To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep --update rock-classifiers/Whats-this-rock/$sweep_id sweep.yaml"
      ],
      "metadata": {
        "id": "bK9aivfKsavT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmN77rpFKDOi"
      },
      "outputs": [],
      "source": [
        "# https://colab.research.google.com/drive/18TOgqiEsKxM0SMuIgBuDllE-dl9iisDz?usp=sharing#scrollTo=goZ3Z7A8nbpn\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"rock_classification\")\n",
        "# wandb.agent(sweep_id, function=train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jMcGudGAUoe"
      },
      "source": [
        "# Deploy Telegram Bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaYiDe5Me-kc"
      },
      "source": [
        "### Uploading secrets with telegram key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hflH5kVue6WT"
      },
      "outputs": [],
      "source": [
        "print(\"Upload secrets.json\")\n",
        "files.upload();"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Whats-this-rock.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}